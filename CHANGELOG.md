# Changelog

All notable changes to promptx will be documented in this file.

## [3.5.2] - 2025-08-06 - MODEL QUALITY GUIDANCE ðŸ“‹

### Improved
- ðŸŽ¯ **Model Size Guidance** - Added important warnings about small models (<7B) producing poor results
- ðŸ“Š **Quality Recommendations** - Emphasized 7B+ models (llama3, mistral, codellama) for best prompt refinement
- ðŸ’¡ **User Education** - Clear parameter counts and quality expectations across all error scenarios
- ðŸ” **Consistent Messaging** - Updated all Ollama error messages with model size recommendations

### Technical Details
- Updated `showOllamaNoModelsError()` with 7B+ model recommendations
- Enhanced model not found errors with quality alternatives
- Improved memory error guidance with size vs quality trade-offs
- Added README note about 7B+ parameter requirement for optimal results

### User Benefits
- Prevents downloading poor-performing small models
- Sets proper expectations for model quality vs size
- Provides specific, actionable model recommendations
- Helps users make informed decisions about local model selection

## [3.5.1] - 2025-08-06 - UI IMPROVEMENTS ðŸŽ¨

### Improved
- ðŸŽ¨ **Cleaner Ollama UI** - Removed scanning messages for streamlined model selection
- âœ¨ **Consistent Experience** - Ollama model selection now matches other providers
- ðŸš€ **Faster Workflow** - Direct model selection without extra status messages

### Technical Details
- Removed "Scanning for local Ollama models..." message
- Removed "âœ… Found X local model(s)" success message
- Users now see model choices directly in the selection prompt
- Maintains all error handling and guidance for failure scenarios

## [3.5.0] - 2025-08-06 - OLLAMA INTEGRATION ðŸ¦™

### Added
- ðŸ¦™ **Ollama Provider Support** - Full integration with local Ollama models
- ðŸ” **Automatic Model Discovery** - Scans and displays locally downloaded Ollama models
- ðŸ›¡ï¸ **Comprehensive Error Handling** - Graceful fallbacks for all Ollama failure scenarios
- ðŸ“‹ **Smart Error Detection** - Specific guidance for installation, service, and model issues
- ðŸ”„ **Graceful Degradation** - Seamless fallback to cloud providers when Ollama fails
- ðŸ’¡ **User Guidance System** - Actionable instructions for each error scenario

### Enhanced
- ðŸš€ **Setup Wizard** - Now includes Ollama as a provider option with error handling
- ðŸ”§ **Model Selection** - Dynamic discovery and selection of local Ollama models
- ðŸŒ **API Integration** - OpenAI-compatible API support for Ollama models
- âš¡ **Streaming Support** - Real-time streaming for Ollama model responses
- ðŸŽ¯ **Error Messages** - Specific, helpful error messages with exact commands to fix issues

### Technical Details
- Added `discoverOllamaModels()` function with comprehensive error detection
- Implemented `checkOllamaService()` for service status verification
- Enhanced setupWizard and changeModel functions with Ollama error handling
- Added specific error guidance functions for each failure scenario
- Integrated Ollama into existing provider selection and configuration system
- Maintained consistency with existing error handling patterns

### Error Scenarios Covered
- **Ollama Not Installed** â†’ Installation instructions with links to https://ollama.ai
- **Service Not Running** â†’ Commands to start Ollama service (`ollama serve`)
- **No Models Downloaded** â†’ Popular model suggestions (`ollama pull llama3`, etc.)
- **API Connection Failures** â†’ Troubleshooting steps and port checking
- **Model Execution Errors** â†’ Memory optimization and model guidance
- **Unknown Errors** â†’ Generic troubleshooting with fallback options

## [3.4.8] - 2025-08-03 - STABLE RELEASE ðŸŽ‰

### Changed
- ðŸŽ¨ Removed ASCII banner for cleaner look
- âœ¨ Simplified "What's New" section to be more concise and appealing
- ðŸ“Š Focused on key features with bold highlights
- ðŸš€ More impactful feature presentation

### Technical Details
- Removed ASCII art logo as requested
- Condensed the feature list to 5 key highlights
- Used bold text for emphasis on important features
- Made the version section shorter and more scannable

## [3.4.7] - 2025-08-03 - STABLE RELEASE ðŸŽ‰

### Added
- ðŸŽ¨ ASCII art promptx logo at the top of README
- ðŸ“Š Enhanced formatting with tables for commands and API keys
- âœ¨ Visual before/after transformation example
- ðŸŽ¯ Better structured sections with emojis
- ðŸ’« Centered header with badges
- ðŸ”— Footer with links to GitHub, issues, and author

### Changed
- ðŸ“ Improved overall README layout and visual appeal
- ðŸ› ï¸ Enhanced troubleshooting section with common issues table
- ðŸ’» Better formatted usage section with clear subsections
- ðŸ“‹ Requirements section now uses a table format

### Technical Details
- ASCII logo prominently displayed at the top
- Centered title and badges for professional look
- Side-by-side transformation example using HTML table
- Consistent emoji usage throughout for visual hierarchy
- Added footer with action links

## [3.4.6] - 2025-08-03 - STABLE RELEASE ðŸŽ‰

### Changed
- ðŸ”„ Reverted README to previous format per user request
- ðŸ“š Restored the original README structure from v3.4.3
- ðŸ”§ Updated version references to v3.4.5

### Technical Details
- README now uses the previous format that was preferred
- Version numbers in README updated to reflect current stable release

## [3.4.5] - 2025-08-03 - STABLE RELEASE ðŸŽ‰

### Changed
- ðŸš¨ Added prominent global install command at the top of README
- âš ï¸ Added warning to use -g flag and not npm's suggested command
- ðŸ“ Restructured README to be more space-efficient
- ðŸ”„ Moved detailed example to collapsible section at the bottom
- âœ¨ Simplified "What is promptx?" section

### Technical Details
- Install command now appears immediately after title
- Clear warning about global installation requirement
- Example transformation now in expandable details section
- More concise introduction section

## [3.4.4] - 2025-08-03 - STABLE RELEASE

### Changed
- ðŸ“š Completely redesigned README with modern structure
- âœ¨ Added comprehensive documentation with tables and examples
- ðŸŽ¨ Better organization with clear sections and navigation
- ðŸ“– Added detailed troubleshooting guide
- ðŸ—ï¸ Professional presentation with badges and formatting

### Added
- ðŸ“Š Model comparison tables with types (Standard/Thinking)
- ðŸ” Before/after prompt transformation example
- ðŸ’¡ Common issues and solutions section
- ðŸ”— Direct links to sections for easy navigation
- ðŸŽ¯ Clear feature categorization

## [3.4.3] - 2025-08-03 - STABLE RELEASE

### Changed
- ðŸ”§ Removed npm version from system prompt for easier maintenance
- ðŸš« Removed Grok 4 Heavy (not available via public API)

### Technical Details
- System prompt no longer contains hardcoded version number
- Removed Grok 4 Heavy from all model lists and documentation
- Only Grok 3, Grok 3 Mini, and Grok 4 are available via xAI API

## [3.4.2] - 2025-08-03 - STABLE RELEASE

### Changed
- ðŸŽ¯ Completely redesigned system prompt for better prompt engineering
- ðŸ¤– Added conversational handling for casual interactions
- ðŸ“ Enhanced prompt engineering principles with 5 comprehensive categories
- âœ¨ Added advanced prompt techniques for complex logic
- ðŸ·ï¸ System prompt now identifies as promptx with creator attribution

### Technical Details
- New system prompt includes:
  - Critical behavior rules for conversational vs prompt requests
  - Ultra-specific objectives guidelines
  - Comprehensive technical requirements structure
  - Implementation guidelines framework
  - AI-optimized structure principles
  - Advanced prompt techniques
- Better handling of edge cases and user intent detection

## [3.4.1] - 2025-08-03 - STABLE RELEASE

### Changed
- ðŸ¤” Marked Gemini 2.5 Pro as a thinking model
- â³ Added thinking spinner for Gemini 2.5 Pro
- ðŸ“ Updated model description to indicate thinking capability

### Technical Details
- Added isThinkingModel flag to Gemini 2.5 Pro configuration
- Thinking spinner appears for Gemini 2.5 Pro until first streaming chunk

## [3.4.0] - 2025-08-03 - STABLE RELEASE

### Added
- ðŸŒŸ Google AI support with Gemini models
- ðŸš€ Gemini 2.5 Flash - Fast and efficient model
- ðŸš€ Gemini 2.0 Flash - Previous flash version
- ðŸš€ Gemini 2.5 Pro - Most capable Gemini model
- ðŸ”‘ Google AI API key setup and validation
- ðŸŽ¯ Full streaming support for Google models

### Changed
- ðŸ“¦ Added @google/generative-ai dependency
- ðŸ¤– Now supports 4 AI providers: OpenAI, Anthropic, xAI, and Google
- ðŸ“š Updated documentation to include Google setup

### Technical Details
- Google AI SDK integration using @google/generative-ai
- Streaming implemented using generateContentStream
- System and user prompts combined for Google's single-prompt format

## [3.3.0] - 2025-08-03 - STABLE RELEASE

### Added
- ðŸš€ GPT-4.1 model support (replaces O3)
- ðŸ¤” Thinking spinner for thinking models (O4 Mini, Grok 4, Grok 4 Heavy)
- â³ Shows "Thinking..." while models process before streaming

### Changed
- ðŸ”„ Replaced O3 model with GPT-4.1
- ðŸ“ Updated model descriptions to indicate thinking models
- ðŸŽ¯ Marked O4 Mini, Grok 4, and Grok 4 Heavy as thinking models

### Technical Details
- Added isThinkingModel flag to model configurations
- Thinking spinner appears until first streaming chunk arrives
- Improved user experience for models with longer initial processing times

## [3.2.4] - 2025-08-03 - STABLE RELEASE

### Fixed
- ðŸ› Fixed O4 Mini and O3 temperature parameter error
- âœ… These models now use default temperature value only

### Technical Details
- O4 Mini and O3 models don't support custom temperature values
- Temperature parameter is now only set for GPT-4o model
- Prevents "Unsupported value: 'temperature'" errors

## [3.2.3] - 2025-08-03 - STABLE RELEASE

### Added
- ðŸ“ Proper word wrapping for streaming output
- ðŸ–¼ï¸ Respects terminal width boundaries
- ðŸ“¦ Added wrap-ansi dependency for better text formatting

### Technical Details
- Streaming output now wraps at terminal boundaries with proper margins
- Prevents text from running to the edge of the terminal
- Handles word breaks intelligently to maintain readability
- Buffer-based approach ensures smooth streaming experience

## [3.2.2] - 2025-08-03 - STABLE RELEASE

### Added
- ðŸš€ Real-time streaming output to terminal
- âœ¨ See refined prompts as they are generated
- ðŸŽ¯ Immediate visual feedback during prompt refinement

### Technical Details
- Removed loading spinner once streaming starts
- Output streams directly to terminal using process.stdout.write
- Consistent formatting across all providers

## [3.2.1] - 2025-08-03 - STABLE RELEASE

### Fixed
- ðŸ› Fixed API streaming errors for long operations across all providers
- âœ… Added proper streaming support for all models to prevent timeout errors

### Enhanced
- ðŸš€ Enabled streaming for OpenAI models (GPT-4o, O4 Mini, O3)
- ðŸš€ Enabled streaming for Anthropic models (Claude Opus 4, Sonnet 4)
- ðŸš€ Enabled streaming for xAI models (Grok 3, Grok 4)

### Technical Details
- All API calls now use `stream: true` parameter
- Properly handles streaming response chunks for reliable operation
- Prevents timeout errors for long-running prompt refinements

## [3.2.0] - 2025-08-03 - STABLE RELEASE

This is the **official stable release** of promptx! This version contains all the essential features and bug fixes for production use.

### What's Included
- âœ… **Complete multi-provider support**: OpenAI, Anthropic, and xAI
- âœ… **All API compatibility issues resolved**: 
  - O4 Mini and O3 models use correct `max_completion_tokens` parameter
  - Claude 4 models use proper identifiers (`claude-opus-4`, `claude-sonnet-4`)
  - Grok 4 reasoning models have correct API parameters
- âœ… **Stable, tested codebase** with no experimental features
- âœ… **Complete feature set**: Interactive wizard, model switching, help system

### Why Upgrade?
- ðŸ”’ **Production ready**: No more beta features or experimental code
- ðŸ› **Bug-free**: All known API compatibility issues resolved
- ðŸš€ **Performance**: Optimized for reliability and speed
- ðŸ“š **Complete documentation**: Full help system and clear usage instructions

**Upgrade command:**
```bash
npm install -g @lukaloehr/promptx@latest
```

## [1.3.1] - 2025-08-02

### Fixed
- ðŸ› Fixed O4 Mini and O3 API errors by using `max_completion_tokens` parameter
- ðŸ”§ Fixed Claude 4 model identifiers (`claude-opus-4`, `claude-sonnet-4`)
- ðŸŽ¯ Updated Grok 4 API parameters (reasoning models don't support temperature)
- ðŸ“ Corrected model descriptions based on latest API documentation

### Changed
- Claude Opus 4 now correctly uses 32k max tokens, Sonnet 4 uses 64k
- Grok 4 models now properly configured as reasoning models
- O4 Mini and O3 use max_completion_tokens instead of max_tokens

## [1.3.0] - 2025-08-02 - Stable Release ðŸŽ‰

### Added
- ðŸ“š `/help` command for quick reference and command overview
- ðŸŽ¯ Complete feature documentation in help menu
- ðŸ“ Comprehensive update history in `/whats-new`
- ðŸ”§ Enhanced package configuration with explicit file lists
- ðŸ“¦ `.npmignore` for cleaner npm packages
- ðŸ”‘ Updated `.env.example` with all provider formats

### Changed
- ðŸŒŸ `/whats-new` now shows complete feature history for stable release
- ðŸ“‹ Improved package metadata and keywords
- ðŸŽ¨ Better organized command documentation

## [1.2.1] - 2025-08-02

### Added
- ðŸ”” Automatic update notifications when new versions are available
- ðŸ“¦ Shows update command in notification: `npm install -g @lukaloehr/promptx`
- â° Update check runs once per day to avoid being intrusive

## [1.2.0] - 2025-08-02

### Added
- ðŸš€ xAI Grok support: Grok 3, Grok 3 Mini, Grok 4, Grok 4 Heavy
- ðŸ§  Updated Claude models: Sonnet 4 and Opus 4
- ðŸ¤– Updated OpenAI models: O4 Mini and O3
- ðŸ“ Organized model selection by provider for better UX
- ðŸŽ¯ Provider-first selection in setup wizard

### Changed
- Models are now grouped by provider in the selection menu
- Improved model descriptions with performance indicators
- Updated API key validation for xAI

## [1.1.0] - 2025-08-02

### Added
- ðŸ¤– Multi-model support: Choose between multiple AI providers
  - OpenAI: GPT-4o, GPT-4o Mini, O3
  - Anthropic: Claude 3.5 Sonnet, Claude 3 Opus
- ðŸ”„ `/model` command: Switch between models on the fly
- âœ¨ Modern setup wizard: Interactive model and API key configuration
- ðŸ“° `/whats-new` command: See latest updates and features
- ðŸ”‘ Support for both OpenAI and Anthropic API keys

### Changed
- Improved first-run experience with guided setup
- Configuration now supports multiple API providers

## [1.0.2] - 2025-08-02

### Added
- ðŸ“¦ NPM badges in README
- âš ï¸ Post-install warning for local installations

### Changed
- Improved installation instructions with emphasis on global installation
- Simplified README structure

## [1.0.1] - 2025-08-02

### Fixed
- Package.json formatting issues
- Installation command documentation

## [1.0.0] - 2025-08-02

### Added
- ðŸŽ‰ Initial release
- âœ¨ Transform messy prompts into structured, clear prompts
- ðŸŽ¨ Beautiful CLI interface with colors and spinners
- ðŸ“¦ Global npm package with easy installation
- ðŸ” Secure API key storage
- ðŸ’» Interactive and direct command-line modes
- ðŸ¤– GPT-4o support for prompt refinement

### Features
- Simple one-command global installation
- First-time setup wizard for API key
- Beautiful colored output
- Loading spinners for better UX
- Error handling with helpful messages
- Command to reset API key