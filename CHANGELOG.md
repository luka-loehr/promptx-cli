# Changelog

All notable changes to promptx will be documented in this file.

## [3.5.3] - 2025-08-06 - PERSISTENT QUALITY RECOMMENDATIONS ğŸ’¡

### Added
- ğŸ¯ **Always-Visible Quality Guidance** - Model recommendation message appears every time user selects Ollama
- ğŸ’¡ **Proactive User Education** - Clear 7B+ parameter recommendation before model selection
- ğŸ”„ **Consistent Experience** - Same guidance in both setup wizard and `/model` command flows
- âš ï¸ **Quality Warnings** - Persistent reminder about smaller models producing poor results

### Enhanced
- ğŸ“‹ **Model Selection UX** - Users now see quality guidance before choosing any Ollama model
- ğŸ¨ **Strategic Positioning** - Recommendation appears right before model selection prompt
- ğŸ’¬ **Clear Messaging** - Specific model recommendations with parameter counts
- ğŸš€ **User Success** - Helps users make informed decisions every time

### Technical Details
- Added quality message in `setupWizard()` after successful Ollama model discovery
- Added quality message in `changeModel()` after successful Ollama model discovery
- Message appears before model selection prompt for maximum visibility
- Maintains clean UI while providing essential quality guidance

## [3.5.2] - 2025-08-06 - MODEL QUALITY GUIDANCE ğŸ“‹

### Improved
- ğŸ¯ **Model Size Guidance** - Added important warnings about small models (<7B) producing poor results
- ğŸ“Š **Quality Recommendations** - Emphasized 7B+ models (llama3, mistral, codellama) for best prompt refinement
- ğŸ’¡ **User Education** - Clear parameter counts and quality expectations across all error scenarios
- ğŸ” **Consistent Messaging** - Updated all Ollama error messages with model size recommendations

### Technical Details
- Updated `showOllamaNoModelsError()` with 7B+ model recommendations
- Enhanced model not found errors with quality alternatives
- Improved memory error guidance with size vs quality trade-offs
- Added README note about 7B+ parameter requirement for optimal results

### User Benefits
- Prevents downloading poor-performing small models
- Sets proper expectations for model quality vs size
- Provides specific, actionable model recommendations
- Helps users make informed decisions about local model selection

## [3.5.1] - 2025-08-06 - UI IMPROVEMENTS ğŸ¨

### Improved
- ğŸ¨ **Cleaner Ollama UI** - Removed scanning messages for streamlined model selection
- âœ¨ **Consistent Experience** - Ollama model selection now matches other providers
- ğŸš€ **Faster Workflow** - Direct model selection without extra status messages

### Technical Details
- Removed "Scanning for local Ollama models..." message
- Removed "âœ… Found X local model(s)" success message
- Users now see model choices directly in the selection prompt
- Maintains all error handling and guidance for failure scenarios

## [3.5.0] - 2025-08-06 - OLLAMA INTEGRATION ğŸ¦™

### Added
- ğŸ¦™ **Ollama Provider Support** - Full integration with local Ollama models
- ğŸ” **Automatic Model Discovery** - Scans and displays locally downloaded Ollama models
- ğŸ›¡ï¸ **Comprehensive Error Handling** - Graceful fallbacks for all Ollama failure scenarios
- ğŸ“‹ **Smart Error Detection** - Specific guidance for installation, service, and model issues
- ğŸ”„ **Graceful Degradation** - Seamless fallback to cloud providers when Ollama fails
- ğŸ’¡ **User Guidance System** - Actionable instructions for each error scenario

### Enhanced
- ğŸš€ **Setup Wizard** - Now includes Ollama as a provider option with error handling
- ğŸ”§ **Model Selection** - Dynamic discovery and selection of local Ollama models
- ğŸŒ **API Integration** - OpenAI-compatible API support for Ollama models
- âš¡ **Streaming Support** - Real-time streaming for Ollama model responses
- ğŸ¯ **Error Messages** - Specific, helpful error messages with exact commands to fix issues

### Technical Details
- Added `discoverOllamaModels()` function with comprehensive error detection
- Implemented `checkOllamaService()` for service status verification
- Enhanced setupWizard and changeModel functions with Ollama error handling
- Added specific error guidance functions for each failure scenario
- Integrated Ollama into existing provider selection and configuration system
- Maintained consistency with existing error handling patterns

### Error Scenarios Covered
- **Ollama Not Installed** â†’ Installation instructions with links to https://ollama.ai
- **Service Not Running** â†’ Commands to start Ollama service (`ollama serve`)
- **No Models Downloaded** â†’ Popular model suggestions (`ollama pull llama3`, etc.)
- **API Connection Failures** â†’ Troubleshooting steps and port checking
- **Model Execution Errors** â†’ Memory optimization and model guidance
- **Unknown Errors** â†’ Generic troubleshooting with fallback options

## [3.4.8] - 2025-08-03 - STABLE RELEASE ğŸ‰

### Changed
- ğŸ¨ Removed ASCII banner for cleaner look
- âœ¨ Simplified "What's New" section to be more concise and appealing
- ğŸ“Š Focused on key features with bold highlights
- ğŸš€ More impactful feature presentation

### Technical Details
- Removed ASCII art logo as requested
- Condensed the feature list to 5 key highlights
- Used bold text for emphasis on important features
- Made the version section shorter and more scannable

## [3.4.7] - 2025-08-03 - STABLE RELEASE ğŸ‰

### Added
- ğŸ¨ ASCII art promptx logo at the top of README
- ğŸ“Š Enhanced formatting with tables for commands and API keys
- âœ¨ Visual before/after transformation example
- ğŸ¯ Better structured sections with emojis
- ğŸ’« Centered header with badges
- ğŸ”— Footer with links to GitHub, issues, and author

### Changed
- ğŸ“ Improved overall README layout and visual appeal
- ğŸ› ï¸ Enhanced troubleshooting section with common issues table
- ğŸ’» Better formatted usage section with clear subsections
- ğŸ“‹ Requirements section now uses a table format

### Technical Details
- ASCII logo prominently displayed at the top
- Centered title and badges for professional look
- Side-by-side transformation example using HTML table
- Consistent emoji usage throughout for visual hierarchy
- Added footer with action links

## [3.4.6] - 2025-08-03 - STABLE RELEASE ğŸ‰

### Changed
- ğŸ”„ Reverted README to previous format per user request
- ğŸ“š Restored the original README structure from v3.4.3
- ğŸ”§ Updated version references to v3.4.5

### Technical Details
- README now uses the previous format that was preferred
- Version numbers in README updated to reflect current stable release

## [3.4.5] - 2025-08-03 - STABLE RELEASE ğŸ‰

### Changed
- ğŸš¨ Added prominent global install command at the top of README
- âš ï¸ Added warning to use -g flag and not npm's suggested command
- ğŸ“ Restructured README to be more space-efficient
- ğŸ”„ Moved detailed example to collapsible section at the bottom
- âœ¨ Simplified "What is promptx?" section

### Technical Details
- Install command now appears immediately after title
- Clear warning about global installation requirement
- Example transformation now in expandable details section
- More concise introduction section

## [3.4.4] - 2025-08-03 - STABLE RELEASE

### Changed
- ğŸ“š Completely redesigned README with modern structure
- âœ¨ Added comprehensive documentation with tables and examples
- ğŸ¨ Better organization with clear sections and navigation
- ğŸ“– Added detailed troubleshooting guide
- ğŸ—ï¸ Professional presentation with badges and formatting

### Added
- ğŸ“Š Model comparison tables with types (Standard/Thinking)
- ğŸ” Before/after prompt transformation example
- ğŸ’¡ Common issues and solutions section
- ğŸ”— Direct links to sections for easy navigation
- ğŸ¯ Clear feature categorization

## [3.4.3] - 2025-08-03 - STABLE RELEASE

### Changed
- ğŸ”§ Removed npm version from system prompt for easier maintenance
- ğŸš« Removed Grok 4 Heavy (not available via public API)

### Technical Details
- System prompt no longer contains hardcoded version number
- Removed Grok 4 Heavy from all model lists and documentation
- Only Grok 3, Grok 3 Mini, and Grok 4 are available via xAI API

## [3.4.2] - 2025-08-03 - STABLE RELEASE

### Changed
- ğŸ¯ Completely redesigned system prompt for better prompt engineering
- ğŸ¤– Added conversational handling for casual interactions
- ğŸ“ Enhanced prompt engineering principles with 5 comprehensive categories
- âœ¨ Added advanced prompt techniques for complex logic
- ğŸ·ï¸ System prompt now identifies as promptx with creator attribution

### Technical Details
- New system prompt includes:
  - Critical behavior rules for conversational vs prompt requests
  - Ultra-specific objectives guidelines
  - Comprehensive technical requirements structure
  - Implementation guidelines framework
  - AI-optimized structure principles
  - Advanced prompt techniques
- Better handling of edge cases and user intent detection

## [3.4.1] - 2025-08-03 - STABLE RELEASE

### Changed
- ğŸ¤” Marked Gemini 2.5 Pro as a thinking model
- â³ Added thinking spinner for Gemini 2.5 Pro
- ğŸ“ Updated model description to indicate thinking capability

### Technical Details
- Added isThinkingModel flag to Gemini 2.5 Pro configuration
- Thinking spinner appears for Gemini 2.5 Pro until first streaming chunk

## [3.4.0] - 2025-08-03 - STABLE RELEASE

### Added
- ğŸŒŸ Google AI support with Gemini models
- ğŸš€ Gemini 2.5 Flash - Fast and efficient model
- ğŸš€ Gemini 2.0 Flash - Previous flash version
- ğŸš€ Gemini 2.5 Pro - Most capable Gemini model
- ğŸ”‘ Google AI API key setup and validation
- ğŸ¯ Full streaming support for Google models

### Changed
- ğŸ“¦ Added @google/generative-ai dependency
- ğŸ¤– Now supports 4 AI providers: OpenAI, Anthropic, xAI, and Google
- ğŸ“š Updated documentation to include Google setup

### Technical Details
- Google AI SDK integration using @google/generative-ai
- Streaming implemented using generateContentStream
- System and user prompts combined for Google's single-prompt format

## [3.3.0] - 2025-08-03 - STABLE RELEASE

### Added
- ğŸš€ GPT-4.1 model support (replaces O3)
- ğŸ¤” Thinking spinner for thinking models (O4 Mini, Grok 4, Grok 4 Heavy)
- â³ Shows "Thinking..." while models process before streaming

### Changed
- ğŸ”„ Replaced O3 model with GPT-4.1
- ğŸ“ Updated model descriptions to indicate thinking models
- ğŸ¯ Marked O4 Mini, Grok 4, and Grok 4 Heavy as thinking models

### Technical Details
- Added isThinkingModel flag to model configurations
- Thinking spinner appears until first streaming chunk arrives
- Improved user experience for models with longer initial processing times

## [3.2.4] - 2025-08-03 - STABLE RELEASE

### Fixed
- ğŸ› Fixed O4 Mini and O3 temperature parameter error
- âœ… These models now use default temperature value only

### Technical Details
- O4 Mini and O3 models don't support custom temperature values
- Temperature parameter is now only set for GPT-4o model
- Prevents "Unsupported value: 'temperature'" errors

## [3.2.3] - 2025-08-03 - STABLE RELEASE

### Added
- ğŸ“ Proper word wrapping for streaming output
- ğŸ–¼ï¸ Respects terminal width boundaries
- ğŸ“¦ Added wrap-ansi dependency for better text formatting

### Technical Details
- Streaming output now wraps at terminal boundaries with proper margins
- Prevents text from running to the edge of the terminal
- Handles word breaks intelligently to maintain readability
- Buffer-based approach ensures smooth streaming experience

## [3.2.2] - 2025-08-03 - STABLE RELEASE

### Added
- ğŸš€ Real-time streaming output to terminal
- âœ¨ See refined prompts as they are generated
- ğŸ¯ Immediate visual feedback during prompt refinement

### Technical Details
- Removed loading spinner once streaming starts
- Output streams directly to terminal using process.stdout.write
- Consistent formatting across all providers

## [3.2.1] - 2025-08-03 - STABLE RELEASE

### Fixed
- ğŸ› Fixed API streaming errors for long operations across all providers
- âœ… Added proper streaming support for all models to prevent timeout errors

### Enhanced
- ğŸš€ Enabled streaming for OpenAI models (GPT-4o, O4 Mini, O3)
- ğŸš€ Enabled streaming for Anthropic models (Claude Opus 4, Sonnet 4)
- ğŸš€ Enabled streaming for xAI models (Grok 3, Grok 4)

### Technical Details
- All API calls now use `stream: true` parameter
- Properly handles streaming response chunks for reliable operation
- Prevents timeout errors for long-running prompt refinements

## [3.2.0] - 2025-08-03 - STABLE RELEASE

This is the **official stable release** of promptx! This version contains all the essential features and bug fixes for production use.

### What's Included
- âœ… **Complete multi-provider support**: OpenAI, Anthropic, and xAI
- âœ… **All API compatibility issues resolved**: 
  - O4 Mini and O3 models use correct `max_completion_tokens` parameter
  - Claude 4 models use proper identifiers (`claude-opus-4`, `claude-sonnet-4`)
  - Grok 4 reasoning models have correct API parameters
- âœ… **Stable, tested codebase** with no experimental features
- âœ… **Complete feature set**: Interactive wizard, model switching, help system

### Why Upgrade?
- ğŸ”’ **Production ready**: No more beta features or experimental code
- ğŸ› **Bug-free**: All known API compatibility issues resolved
- ğŸš€ **Performance**: Optimized for reliability and speed
- ğŸ“š **Complete documentation**: Full help system and clear usage instructions

**Upgrade command:**
```bash
npm install -g @lukaloehr/promptx@latest
```

## [1.3.1] - 2025-08-02

### Fixed
- ğŸ› Fixed O4 Mini and O3 API errors by using `max_completion_tokens` parameter
- ğŸ”§ Fixed Claude 4 model identifiers (`claude-opus-4`, `claude-sonnet-4`)
- ğŸ¯ Updated Grok 4 API parameters (reasoning models don't support temperature)
- ğŸ“ Corrected model descriptions based on latest API documentation

### Changed
- Claude Opus 4 now correctly uses 32k max tokens, Sonnet 4 uses 64k
- Grok 4 models now properly configured as reasoning models
- O4 Mini and O3 use max_completion_tokens instead of max_tokens

## [1.3.0] - 2025-08-02 - Stable Release ğŸ‰

### Added
- ğŸ“š `/help` command for quick reference and command overview
- ğŸ¯ Complete feature documentation in help menu
- ğŸ“ Comprehensive update history in `/whats-new`
- ğŸ”§ Enhanced package configuration with explicit file lists
- ğŸ“¦ `.npmignore` for cleaner npm packages
- ğŸ”‘ Updated `.env.example` with all provider formats

### Changed
- ğŸŒŸ `/whats-new` now shows complete feature history for stable release
- ğŸ“‹ Improved package metadata and keywords
- ğŸ¨ Better organized command documentation

## [1.2.1] - 2025-08-02

### Added
- ğŸ”” Automatic update notifications when new versions are available
- ğŸ“¦ Shows update command in notification: `npm install -g @lukaloehr/promptx`
- â° Update check runs once per day to avoid being intrusive

## [1.2.0] - 2025-08-02

### Added
- ğŸš€ xAI Grok support: Grok 3, Grok 3 Mini, Grok 4, Grok 4 Heavy
- ğŸ§  Updated Claude models: Sonnet 4 and Opus 4
- ğŸ¤– Updated OpenAI models: O4 Mini and O3
- ğŸ“ Organized model selection by provider for better UX
- ğŸ¯ Provider-first selection in setup wizard

### Changed
- Models are now grouped by provider in the selection menu
- Improved model descriptions with performance indicators
- Updated API key validation for xAI

## [1.1.0] - 2025-08-02

### Added
- ğŸ¤– Multi-model support: Choose between multiple AI providers
  - OpenAI: GPT-4o, GPT-4o Mini, O3
  - Anthropic: Claude 3.5 Sonnet, Claude 3 Opus
- ğŸ”„ `/model` command: Switch between models on the fly
- âœ¨ Modern setup wizard: Interactive model and API key configuration
- ğŸ“° `/whats-new` command: See latest updates and features
- ğŸ”‘ Support for both OpenAI and Anthropic API keys

### Changed
- Improved first-run experience with guided setup
- Configuration now supports multiple API providers

## [1.0.2] - 2025-08-02

### Added
- ğŸ“¦ NPM badges in README
- âš ï¸ Post-install warning for local installations

### Changed
- Improved installation instructions with emphasis on global installation
- Simplified README structure

## [1.0.1] - 2025-08-02

### Fixed
- Package.json formatting issues
- Installation command documentation

## [1.0.0] - 2025-08-02

### Added
- ğŸ‰ Initial release
- âœ¨ Transform messy prompts into structured, clear prompts
- ğŸ¨ Beautiful CLI interface with colors and spinners
- ğŸ“¦ Global npm package with easy installation
- ğŸ” Secure API key storage
- ğŸ’» Interactive and direct command-line modes
- ğŸ¤– GPT-4o support for prompt refinement

### Features
- Simple one-command global installation
- First-time setup wizard for API key
- Beautiful colored output
- Loading spinners for better UX
- Error handling with helpful messages
- Command to reset API key